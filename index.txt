3:I[6871,["98","static/chunks/98-98337b3bb708bd24.js","748","static/chunks/748-1f14ee6eb3d7029a.js","271","static/chunks/271-37a22bace913f735.js","185","static/chunks/app/layout-08611f287dda1230.js"],"default"]
4:I[5877,["98","static/chunks/98-98337b3bb708bd24.js","748","static/chunks/748-1f14ee6eb3d7029a.js","271","static/chunks/271-37a22bace913f735.js","185","static/chunks/app/layout-08611f287dda1230.js"],"default"]
5:I[902,["98","static/chunks/98-98337b3bb708bd24.js","748","static/chunks/748-1f14ee6eb3d7029a.js","271","static/chunks/271-37a22bace913f735.js","185","static/chunks/app/layout-08611f287dda1230.js"],""]
6:I[9275,[],""]
7:I[1343,[],""]
8:I[5218,["98","static/chunks/98-98337b3bb708bd24.js","134","static/chunks/134-4d46f2c5e7204b76.js","830","static/chunks/830-8a0df588e7c84864.js","931","static/chunks/app/page-93babc7be28378fd.js"],""]
9:I[2324,["98","static/chunks/98-98337b3bb708bd24.js","134","static/chunks/134-4d46f2c5e7204b76.js","830","static/chunks/830-8a0df588e7c84864.js","931","static/chunks/app/page-93babc7be28378fd.js"],"default"]
a:I[2591,["98","static/chunks/98-98337b3bb708bd24.js","134","static/chunks/134-4d46f2c5e7204b76.js","830","static/chunks/830-8a0df588e7c84864.js","931","static/chunks/app/page-93babc7be28378fd.js"],""]
b:I[231,["98","static/chunks/98-98337b3bb708bd24.js","134","static/chunks/134-4d46f2c5e7204b76.js","830","static/chunks/830-8a0df588e7c84864.js","931","static/chunks/app/page-93babc7be28378fd.js"],""]
c:I[3180,["98","static/chunks/98-98337b3bb708bd24.js","134","static/chunks/134-4d46f2c5e7204b76.js","160","static/chunks/app/not-found-cede9e206a912af9.js"],""]
d:I[3245,["98","static/chunks/98-98337b3bb708bd24.js","748","static/chunks/748-1f14ee6eb3d7029a.js","271","static/chunks/271-37a22bace913f735.js","185","static/chunks/app/layout-08611f287dda1230.js"],"default"]
0:["WaLb_sZ3RF-6dnakeG92A",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},[["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__className_d65c78","children":["$","$L3",null,{"children":[["$","$L4",null,{}],["$","$L5",null,{"maxWidth":"lg","children":[["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","$L8",null,{"children":[["$","$L9",null,{"render":false,"targetSiteNavigationState":[],"targetPageNavigationState":[]}],["$","$La",null,{"variant":"h4","children":["$","strong",null,{"children":"Not Found"}]}],["$","$La",null,{"variant":"h6","mb":3,"children":"Oops! It looks like the page you're looking for does not exist."}],["$","$Lb",null,{"href":"/","children":["$","$Lc",null,{"variant":"contained","sx":{"marginRight":5,"marginBottom":1},"children":"Take me Home"}]}]]}],"notFoundStyles":[],"styles":null}],["$","$Ld",null,{}]]}]]}]}]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/1d4d01086947be98.css","precedence":"next","crossOrigin":"$undefined"}]],"$Le"]]]]
e:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","link","2",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
1:null
f:I[3507,["98","static/chunks/98-98337b3bb708bd24.js","134","static/chunks/134-4d46f2c5e7204b76.js","830","static/chunks/830-8a0df588e7c84864.js","931","static/chunks/app/page-93babc7be28378fd.js"],""]
10:I[6652,["98","static/chunks/98-98337b3bb708bd24.js","134","static/chunks/134-4d46f2c5e7204b76.js","830","static/chunks/830-8a0df588e7c84864.js","931","static/chunks/app/page-93babc7be28378fd.js"],""]
11:I[6981,["98","static/chunks/98-98337b3bb708bd24.js","134","static/chunks/134-4d46f2c5e7204b76.js","830","static/chunks/830-8a0df588e7c84864.js","931","static/chunks/app/page-93babc7be28378fd.js"],""]
12:I[2818,["98","static/chunks/98-98337b3bb708bd24.js","134","static/chunks/134-4d46f2c5e7204b76.js","830","static/chunks/830-8a0df588e7c84864.js","931","static/chunks/app/page-93babc7be28378fd.js"],""]
2:["$","$L8",null,{"mb":5,"pb":2,"children":[["$","$L9",null,{"render":false,"targetSiteNavigationState":[],"targetPageNavigationState":[{"absoluteSlug":"/full-stack/3d-slicer-extension-tutorials","title":"3D Slicer Extension Tutorials"},{"absoluteSlug":"/ml-ops/fastapi-onnx-backend","title":"Serving an ONNX Model using FastAPI"},{"absoluteSlug":"/dev-ops/setting-up-a-dev-kubernetes-cluster","title":"Setting Up a Development Kubernetes Cluster"},{"absoluteSlug":"/sde/structuring-codebases-with-common-files","title":"Three ways to Structure a Codebase containing Multiple Applications"},{"absoluteSlug":"/ml-ops/total-segmentator-api-with-huey","title":"Running ML inference through a Huey Task Queue and FastAPI"},{"absoluteSlug":"/ml-ops/torch-training-and-conversion-to-onnx","title":"Training a CNN in PyTorch and Exporting it to ONNX"},{"absoluteSlug":"/ml-ops/onnxruntime-web-inference-in-react","title":"ONNXRuntime Inference in a React App"},{"absoluteSlug":"/full-stack/react-konva-draw-image-and-predict-via-api","title":"Drawing Images in React using Konva and extracting Image Arrays"},{"absoluteSlug":"/ml-ops/tensorflow-training-plus-conversion-to-onnx-and-tfjs","title":"Training a CNN in TensorFlow and Exporting it to ONNX and TFJS"},{"absoluteSlug":"/ml-ops/fastapi-tensorflow-backend","title":"Serving a TensorFlow Model using FastAPI"},{"absoluteSlug":"/ml-ops/gpu-vs-cpu-performance-for-ml-inference-workflows","title":"ML Inference Performance on GPU and CPU across different batch sizes."},{"absoluteSlug":"/ml-ops/ml-inference-on-backend-vs-frontend","title":"ML Inference on Backend vs Frontend"},{"absoluteSlug":"/dev-ops/diy-weighted-load-balancing-python","title":"DIY Weighted Load Balancing in Python"},{"absoluteSlug":"/ml-ops/tensorflow-js-inference-in-react","title":"TensorFlow.js Inference in React on an image drawn with Konva"},{"absoluteSlug":"/ml-ops/node-express-onnx-backend","title":"Express.js API for Inference using an ONNX Model"},{"absoluteSlug":"/ml-ops/fastapi-torch-backend","title":"Serving a PyTorch Model using FastAPI"}]}],["$","$Lf",null,{"container":true,"spacing":2,"mb":6,"children":[["$","$Lf","dev-ops",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/dev-ops","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/dev-ops-category-thumbnail.jpg","alt":"Dev Ops","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":["$","$La",null,{"gutterBottom":true,"variant":"h5","component":"h2","children":"Dev Ops"}]}]]}]}]}],["$","$Lf","full-stack",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/full-stack","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/full-stack-category-thumbnail.jpg","alt":"Full Stack","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":["$","$La",null,{"gutterBottom":true,"variant":"h5","component":"h2","children":"Full Stack"}]}]]}]}]}],["$","$Lf","ml-ops",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/ml-ops-category-thumbnail.jpg","alt":"ML Ops","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":["$","$La",null,{"gutterBottom":true,"variant":"h5","component":"h2","children":"ML Ops"}]}]]}]}]}],["$","$Lf","sde",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/sde","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/sde-category-thumbnail.jpg","alt":"Software Engineering","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":["$","$La",null,{"gutterBottom":true,"variant":"h5","component":"h2","children":"Software Engineering"}]}]]}]}]}]]}],["$","$Lf",null,{"container":true,"spacing":2,"mt":4,"mb":4,"children":[["$","$Lf","/full-stack/3d-slicer-extension-tutorials",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/full-stack/3d-slicer-extension-tutorials","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/3d-slicer-extension-tutorials-series-thumbnails.jpg","alt":"3D Slicer Extension Tutorials","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","3D Slicer Extension Tutorials"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Learn how to create an extension for 3D Slicer: extract volumes and slices, run ML models, edit segmentations, and much more."}],false,["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"space-between","alignItems":"center"},"children":[["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"3 Parts"}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"24m Read"}]]}]]}]]}]}]}],["$","$Lf","/ml-ops/fastapi-onnx-backend",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/fastapi-onnx-backend","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/fastapi-onnx-backend-thumbnail.jpg","alt":"Serving an ONNX Model using FastAPI","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Serving an ONNX Model using FastAPI"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Learn how to serve an ONNX model with FastAPI."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"06m Read"}]}],false]}]]}]}]}],["$","$Lf","/dev-ops/setting-up-a-dev-kubernetes-cluster",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/dev-ops/setting-up-a-dev-kubernetes-cluster","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/structuring-codebases-with-common-files-thumbnail.jpg","alt":"Setting Up a Development Kubernetes Cluster","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Setting Up a Development Kubernetes Cluster"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Set up a single-node Kubernetes Cluster (minikube) as well as other tools (Kubectl, Helm, KEDA, etc.) on your local machine."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"05m Read"}]}],false]}]]}]}]}],["$","$Lf","/sde/structuring-codebases-with-common-files",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/sde/structuring-codebases-with-common-files","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/structuring-codebases-with-common-files-thumbnail.jpg","alt":"Three ways to Structure a Codebase containing Multiple Applications","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Three ways to Structure a Codebase containing Multiple Applications"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"It is common to find codebases (monorepos) in which logic is repeated across multiple applications. We evaluate three ways to structure such codebases for ease of development, version control, and deployment."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"06m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/total-segmentator-api-with-huey",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/total-segmentator-api-with-huey","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/total-segmentator-api-with-huey-system-architecture-diagram.jpg","alt":"Running ML inference through a Huey Task Queue and FastAPI","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Running ML inference through a Huey Task Queue and FastAPI"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Learn how to train a simple CNN in PyTorch and how to convert it to ONNX for deployment."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"07m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/torch-training-and-conversion-to-onnx",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/torch-training-and-conversion-to-onnx","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/torch-training-and-conversion-to-onnx-thumbnail.jpg","alt":"Training a CNN in PyTorch and Exporting it to ONNX","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Training a CNN in PyTorch and Exporting it to ONNX"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Learn how to train a simple CNN in PyTorch and how to convert it to ONNX for deployment."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"07m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/onnxruntime-web-inference-in-react",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/onnxruntime-web-inference-in-react","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/react-digit-recog-app-final.jpg","alt":"ONNXRuntime Inference in a React App","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","ONNXRuntime Inference in a React App"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Inferencing on an ONNX model in a React App using ONNXRuntime Web."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"08m Read"}]}],false]}]]}]}]}],["$","$Lf","/full-stack/react-konva-draw-image-and-predict-via-api",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/full-stack/react-konva-draw-image-and-predict-via-api","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/react-konva-draw-image-and-predict-via-api-thumbnail.jpg","alt":"Drawing Images in React using Konva and extracting Image Arrays","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Drawing Images in React using Konva and extracting Image Arrays"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Konva.js is a 2D Canvas Library for the web. We'll draw an image using Konva, extract the image array, and call an API to run an ML model on the image."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"07m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/tensorflow-training-plus-conversion-to-onnx-and-tfjs",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/tensorflow-training-plus-conversion-to-onnx-and-tfjs","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/tensorflow-training-plus-conversion-to-onnx-and-tfjs-thumbnail.jpg","alt":"Training a CNN in TensorFlow and Exporting it to ONNX and TFJS","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Training a CNN in TensorFlow and Exporting it to ONNX and TFJS"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Learn how to train a simple CNN in TensorFlow and how to convert it to ONNX or TensorFlow.js for deployment."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"05m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/fastapi-tensorflow-backend",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/fastapi-tensorflow-backend","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/fastapi-tensorflow-backend-thumbnail.jpg","alt":"Serving a TensorFlow Model using FastAPI","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Serving a TensorFlow Model using FastAPI"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Learn how to serve a TensorFlow model with FastAPI."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"05m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/gpu-vs-cpu-performance-for-ml-inference-workflows",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/gpu-vs-cpu-performance-for-ml-inference-workflows","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/gpu-vs-cpu-performance-for-ml-inference-workflows-thumbnail.jpg","alt":"ML Inference Performance on GPU and CPU across different batch sizes.","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","ML Inference Performance on GPU and CPU across different batch sizes."]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"A comparison of ML inference speed and memory consumption across various batch sizes on both GPU and CPU."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"08m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/ml-inference-on-backend-vs-frontend",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/ml-inference-on-backend-vs-frontend","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/ml-inference-on-backend-vs-frontend-thumbnail.jpg","alt":"ML Inference on Backend vs Frontend","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","ML Inference on Backend vs Frontend"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"A comparison of ML inference speed and memory consumption across various batch sizes on both GPU and CPU."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"05m Read"}]}],false]}]]}]}]}],["$","$Lf","/dev-ops/diy-weighted-load-balancing-python",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/dev-ops/diy-weighted-load-balancing-python","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/diy-weighted-load-balancing-python-thumbnail.jpg","alt":"DIY Weighted Load Balancing in Python","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","DIY Weighted Load Balancing in Python"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Set up a single-node Kubernetes Cluster (minikube) as well as other tools (Kubectl, Helm, KEDA, etc.) on your local machine."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"04m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/tensorflow-js-inference-in-react",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/tensorflow-js-inference-in-react","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/react-digit-recog-app-final.jpg","alt":"TensorFlow.js Inference in React on an image drawn with Konva","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","TensorFlow.js Inference in React on an image drawn with Konva"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Inferencing on an ONNX model in a React App using ONNXRuntime Web."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"08m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/node-express-onnx-backend",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/node-express-onnx-backend","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/node-express-onnx-backend-thumbnail.jpg","alt":"Express.js API for Inference using an ONNX Model","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Express.js API for Inference using an ONNX Model"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Deploying an ONNX Model using Express.js."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"08m Read"}]}],false]}]]}]}]}],["$","$Lf","/ml-ops/fastapi-torch-backend",{"item":true,"xs":12,"sm":6,"md":4,"lg":3,"children":["$","$Lb",null,{"href":"/ml-ops/fastapi-torch-backend","passHref":true,"style":{"textDecoration":"none"},"children":["$","$L10",null,{"sx":{"width":"100%","height":"100%","boxShadow":"1px 1px 1px 1px \"#eeeeee\"","&:hover":{"boxShadow":"3px 3px 3px 3px \"#eeeeee\"","cursor":"pointer"}},"children":[["$","$L11",null,{"component":"img","height":"150","image":"/media/images/fastapi-torch-backend-thumbnail.jpg","alt":"Serving a PyTorch Model using FastAPI","sx":{"objectFit":"cover"}}],["$","$L12",null,{"children":[["$","$La",null,{"gutterBottom":true,"variant":"h6","component":"h2","children":[""," ","Serving a PyTorch Model using FastAPI"]}],["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","sx":{"overflow":"hidden","textOverflow":"ellipsis","display":"-webkit-box","WebkitLineClamp":"3","WebkitBoxOrient":"vertical"},"children":"Learn how to serve a PyTorch model with FastAPI."}],["$","$L8",null,{"sx":{"width":"100%","display":"flex","flexDirection":"row","justifyContent":"flex-end","alignItems":"center"},"children":["$","$La",null,{"gutterBottom":true,"variant":"p","component":"p","children":"06m Read"}]}],false]}]]}]}]}]]}]]}]
