<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/media/images/main-contact-email-light.jpg"/><link rel="preload" as="image" href="/media/images/ml-inference-on-backend-vs-frontend-thumbnail.jpg"/><link rel="preload" as="image" href="/media/images/gpu-vs-cpu-performance-for-ml-inference-workflows-thumbnail.jpg"/><link rel="preload" as="image" href="/media/images/fastapi-onnx-backend-thumbnail.jpg"/><link rel="preload" as="image" href="/media/images/node-express-onnx-backend-thumbnail.jpg"/><link rel="preload" as="image" href="/media/images/react-digit-recog-app-final.jpg"/><link rel="stylesheet" href="/_next/static/css/1d4d01086947be98.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-83486951edee0db5.js"/><script src="/_next/static/chunks/fd9d1056-90960e0a7e77703c.js" async=""></script><script src="/_next/static/chunks/23-365ff0b9e0ad811d.js" async=""></script><script src="/_next/static/chunks/main-app-37d3bbd360c1bff1.js" async=""></script><script src="/_next/static/chunks/98-7f6363f9ac68c942.js" async=""></script><script src="/_next/static/chunks/748-1f14ee6eb3d7029a.js" async=""></script><script src="/_next/static/chunks/271-37a22bace913f735.js" async=""></script><script src="/_next/static/chunks/app/layout-08611f287dda1230.js" async=""></script><script src="/_next/static/chunks/134-9729e0afcc6dfdfe.js" async=""></script><script src="/_next/static/chunks/830-8a0df588e7c84864.js" async=""></script><script src="/_next/static/chunks/411-e5dcfc2304d91b2f.js" async=""></script><script src="/_next/static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js" async=""></script><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_d65c78"><header style="margin-bottom:25px"><style data-emotion="css 13x2oq7">.css-13x2oq7{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:fixed;z-index:1100;top:0;left:auto;right:0;background-color:#1976d2;color:#fff;}@media print{.css-13x2oq7{position:absolute;}}</style><style data-emotion="css 5poeop">.css-5poeop{background-color:#fff;color:rgba(0, 0, 0, 0.87);-webkit-transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;box-shadow:0px 2px 4px -1px rgba(0,0,0,0.2),0px 4px 5px 0px rgba(0,0,0,0.14),0px 1px 10px 0px rgba(0,0,0,0.12);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;box-sizing:border-box;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;position:fixed;z-index:1100;top:0;left:auto;right:0;background-color:#1976d2;color:#fff;}@media print{.css-5poeop{position:absolute;}}</style><header class="MuiPaper-root MuiPaper-elevation MuiPaper-elevation4 MuiAppBar-root MuiAppBar-colorPrimary MuiAppBar-positionFixed mui-fixed css-5poeop"><style data-emotion="css 1qsxih2">.css-1qsxih2{width:100%;margin-left:auto;box-sizing:border-box;margin-right:auto;display:block;padding-left:16px;padding-right:16px;}@media (min-width:600px){.css-1qsxih2{padding-left:24px;padding-right:24px;}}@media (min-width:1200px){.css-1qsxih2{max-width:1200px;}}</style><div class="MuiContainer-root MuiContainer-maxWidthLg css-1qsxih2"><style data-emotion="css r4h1bh">.css-r4h1bh{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;padding-right:16px;min-height:56px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;padding:0px;}@media (min-width:600px){.css-r4h1bh{padding-left:24px;padding-right:24px;}}@media (min-width:0px){@media (orientation: landscape){.css-r4h1bh{min-height:48px;}}}@media (min-width:600px){.css-r4h1bh{min-height:64px;}}</style><div class="MuiToolbar-root MuiToolbar-gutters MuiToolbar-regular css-r4h1bh"><style data-emotion="css 1pna09g">.css-1pna09g{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:2.125rem;line-height:1.235;letter-spacing:0.00735em;font-weight:700;text-align:center;background:linear-gradient(45deg, #FFD700 30%, #FFA500 90%);-webkit-background-clip:text;-webkit-text-fill-color:transparent;}.css-1pna09g:hover{cursor:pointer;}</style><h4 class="MuiTypography-root MuiTypography-h4 css-1pna09g">A.N.T</h4><div class="MuiBox-root css-0"><style data-emotion="css j4ylzh">.css-j4ylzh{text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;overflow:visible;color:rgba(0, 0, 0, 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#ed6c02;}.css-j4ylzh:hover{background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-j4ylzh:hover{background-color:transparent;}}.css-j4ylzh:hover{background-color:rgba(237, 108, 2, 0.04);}@media (hover: none){.css-j4ylzh:hover{background-color:transparent;}}.css-j4ylzh.Mui-disabled{background-color:transparent;color:rgba(0, 0, 0, 0.26);}</style><style data-emotion="css r4nl99">.css-r4nl99{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;overflow:visible;color:rgba(0, 0, 0, 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#ed6c02;}.css-r4nl99::-moz-focus-inner{border-style:none;}.css-r4nl99.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-r4nl99{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-r4nl99:hover{background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-r4nl99:hover{background-color:transparent;}}.css-r4nl99:hover{background-color:rgba(237, 108, 2, 0.04);}@media (hover: none){.css-r4nl99:hover{background-color:transparent;}}.css-r4nl99.Mui-disabled{background-color:transparent;color:rgba(0, 0, 0, 0.26);}</style><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorWarning MuiIconButton-sizeMedium css-r4nl99" tabindex="0" type="button"><style data-emotion="css 6flbmm">.css-6flbmm{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;fill:currentColor;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;font-size:2.1875rem;}</style><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeLarge css-6flbmm" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="MenuIcon"><path d="M3 18h18v-2H3zm0-5h18v-2H3zm0-7v2h18V6z"></path></svg></button></div></div></div></header><div style="padding-top:55px"></div> </header><style data-emotion="css 1qsxih2">.css-1qsxih2{width:100%;margin-left:auto;box-sizing:border-box;margin-right:auto;display:block;padding-left:16px;padding-right:16px;}@media (min-width:600px){.css-1qsxih2{padding-left:24px;padding-right:24px;}}@media (min-width:1200px){.css-1qsxih2{max-width:1200px;}}</style><div class="MuiContainer-root MuiContainer-maxWidthLg css-1qsxih2"><style data-emotion="css 1g0xyuw">.css-1g0xyuw{margin-bottom:40px;padding-bottom:16px;width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}</style><div class="MuiBox-root css-1g0xyuw"><style data-emotion="css 1vl439b">.css-1vl439b{width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-bottom:24px;}@media (min-width:0px){.css-1vl439b{display:none;}}@media (min-width:900px){.css-1vl439b{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}</style><div class="MuiBox-root css-1vl439b"><style data-emotion="css 1yae3jf">.css-1yae3jf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="MuiBox-root css-1yae3jf"><a href="/"><style data-emotion="css pbbsfi">.css-pbbsfi{font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:500;font-size:0.8125rem;line-height:1.75;letter-spacing:0.02857em;text-transform:uppercase;min-width:64px;padding:3px 9px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;border:1px solid rgba(237, 108, 2, 0.5);color:#ed6c02;}.css-pbbsfi:hover{-webkit-text-decoration:none;text-decoration:none;background-color:rgba(237, 108, 2, 0.04);border:1px solid #ed6c02;}@media (hover: none){.css-pbbsfi:hover{background-color:transparent;}}.css-pbbsfi.Mui-disabled{color:rgba(0, 0, 0, 0.26);border:1px solid rgba(0, 0, 0, 0.12);}</style><style data-emotion="css 1184ln1">.css-1184ln1{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:500;font-size:0.8125rem;line-height:1.75;letter-spacing:0.02857em;text-transform:uppercase;min-width:64px;padding:3px 9px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;border:1px solid rgba(237, 108, 2, 0.5);color:#ed6c02;}.css-1184ln1::-moz-focus-inner{border-style:none;}.css-1184ln1.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-1184ln1{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-1184ln1:hover{-webkit-text-decoration:none;text-decoration:none;background-color:rgba(237, 108, 2, 0.04);border:1px solid #ed6c02;}@media (hover: none){.css-1184ln1:hover{background-color:transparent;}}.css-1184ln1.Mui-disabled{color:rgba(0, 0, 0, 0.26);border:1px solid rgba(0, 0, 0, 0.12);}</style><button class="MuiButtonBase-root MuiButton-root MuiButton-outlined MuiButton-outlinedWarning MuiButton-sizeSmall MuiButton-outlinedSizeSmall MuiButton-colorWarning MuiButton-root MuiButton-outlined MuiButton-outlinedWarning MuiButton-sizeSmall MuiButton-outlinedSizeSmall MuiButton-colorWarning css-1184ln1" tabindex="0" type="button">Home</button></a></div><div class="MuiBox-root css-1yae3jf"><style data-emotion="css vubbuv">.css-vubbuv{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;fill:currentColor;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;font-size:1.5rem;}</style><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="KeyboardArrowRightIcon"><path d="M8.59 16.59 13.17 12 8.59 7.41 10 6l6 6-6 6z"></path></svg><a href="/ml-ops/"><button class="MuiButtonBase-root MuiButton-root MuiButton-outlined MuiButton-outlinedWarning MuiButton-sizeSmall MuiButton-outlinedSizeSmall MuiButton-colorWarning MuiButton-root MuiButton-outlined MuiButton-outlinedWarning MuiButton-sizeSmall MuiButton-outlinedSizeSmall MuiButton-colorWarning css-1184ln1" tabindex="0" type="button">ML Ops</button></a></div><div class="MuiBox-root css-1yae3jf"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="KeyboardArrowRightIcon"><path d="M8.59 16.59 13.17 12 8.59 7.41 10 6l6 6-6 6z"></path></svg><a href="/ml-ops/ml-inference-on-backend-vs-frontend/"><button class="MuiButtonBase-root MuiButton-root MuiButton-outlined MuiButton-outlinedWarning MuiButton-sizeSmall MuiButton-outlinedSizeSmall MuiButton-colorWarning MuiButton-root MuiButton-outlined MuiButton-outlinedWarning MuiButton-sizeSmall MuiButton-outlinedSizeSmall MuiButton-colorWarning css-1184ln1" tabindex="0" type="button">ML Inference on Backend vs Frontend</button></a></div></div><style data-emotion="css slaq2o">.css-slaq2o{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-16px;width:calc(100% + 16px);margin-left:-16px;margin-bottom:0px;}.css-slaq2o>.MuiGrid-item{padding-top:16px;}.css-slaq2o>.MuiGrid-item{padding-left:16px;}</style><div class="MuiGrid-root MuiGrid-container MuiGrid-spacing-xs-2 css-slaq2o"><style data-emotion="css hr4540">.css-hr4540{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;background:linear-gradient(to right, #eeeeee, #ffffff);border-radius:20px;}@media (min-width:600px){.css-hr4540{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:900px){.css-hr4540{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}@media (min-width:1200px){.css-hr4540{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}@media (min-width:1536px){.css-hr4540{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-12 MuiGrid-grid-md-4 css-hr4540"><style data-emotion="css 194lag7">.css-194lag7{width:100%;height:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;padding-bottom:16px;}</style><div class="MuiBox-root css-194lag7"><style data-emotion="css t1nuxs">.css-t1nuxs{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1.5rem;line-height:1.334;letter-spacing:0em;margin-bottom:0.35em;}</style><h1 class="MuiTypography-root MuiTypography-h5 MuiTypography-gutterBottom css-t1nuxs">ML Inference on Backend vs Frontend</h1><style data-emotion="css 15wzlf5">.css-15wzlf5{margin:0;margin-bottom:0.35em;margin-bottom:32px;}</style><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-15wzlf5">A comparison of ML inference speed and memory consumption across various batch sizes on both GPU and CPU.</p><style data-emotion="css 1aiyebw">.css-1aiyebw{width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-bottom:16px;}</style><div class="MuiBox-root css-1aiyebw"><style data-emotion="css mxjm1x">.css-mxjm1x{margin:0;margin-bottom:0.35em;}</style><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-mxjm1x">June 17, 2024</p><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-mxjm1x">05m<!-- --> Read</p></div><style data-emotion="css 1sdy4c7">.css-1sdy4c7{width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="MuiBox-root css-1sdy4c7"><style data-emotion="css 19115x2">.css-19115x2{margin:0;margin-right:16px;}</style><p class="MuiTypography-root MuiTypography-p css-19115x2">By: Abhilaksh Singh Reen</p><style data-emotion="css o6eoqx">.css-o6eoqx{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:space-evenly;-ms-flex-pack:space-evenly;-webkit-justify-content:space-evenly;justify-content:space-evenly;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="MuiBox-root css-o6eoqx"><style data-emotion="css 1t2xui4">.css-1t2xui4{text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;overflow:visible;color:rgba(0, 0, 0, 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#0077B5;}.css-1t2xui4:hover{background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-1t2xui4:hover{background-color:transparent;}}.css-1t2xui4.Mui-disabled{background-color:transparent;color:rgba(0, 0, 0, 0.26);}</style><style data-emotion="css 1yl6xtp">.css-1yl6xtp{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;overflow:visible;color:rgba(0, 0, 0, 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#0077B5;}.css-1yl6xtp::-moz-focus-inner{border-style:none;}.css-1yl6xtp.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-1yl6xtp{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-1yl6xtp:hover{background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-1yl6xtp:hover{background-color:transparent;}}.css-1yl6xtp.Mui-disabled{background-color:transparent;color:rgba(0, 0, 0, 0.26);}</style><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeMedium css-1yl6xtp" tabindex="0" type="button"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="LinkedInIcon"><path d="M19 3a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h14m-.5 15.5v-5.3a3.26 3.26 0 0 0-3.26-3.26c-.85 0-1.84.52-2.32 1.3v-1.11h-2.79v8.37h2.79v-4.93c0-.77.62-1.4 1.39-1.4a1.4 1.4 0 0 1 1.4 1.4v4.93h2.79M6.88 8.56a1.68 1.68 0 0 0 1.68-1.68c0-.93-.75-1.69-1.68-1.69a1.69 1.69 0 0 0-1.69 1.69c0 .93.76 1.68 1.69 1.68m1.39 9.94v-8.37H5.5v8.37h2.77z"></path></svg></button><style data-emotion="css 161nngb">.css-161nngb{text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;overflow:visible;color:rgba(0, 0, 0, 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#000000;}.css-161nngb:hover{background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-161nngb:hover{background-color:transparent;}}.css-161nngb.Mui-disabled{background-color:transparent;color:rgba(0, 0, 0, 0.26);}</style><style data-emotion="css tn2bks">.css-tn2bks{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;overflow:visible;color:rgba(0, 0, 0, 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#000000;}.css-tn2bks::-moz-focus-inner{border-style:none;}.css-tn2bks.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-tn2bks{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-tn2bks:hover{background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-tn2bks:hover{background-color:transparent;}}.css-tn2bks.Mui-disabled{background-color:transparent;color:rgba(0, 0, 0, 0.26);}</style><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeMedium css-tn2bks" tabindex="0" type="button"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="XIcon"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"></path></svg></button><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeMedium css-tn2bks" tabindex="0" type="button"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="GitHubIcon"><path d="M12 1.27a11 11 0 00-3.48 21.46c.55.09.73-.28.73-.55v-1.84c-3.03.64-3.67-1.46-3.67-1.46-.55-1.29-1.28-1.65-1.28-1.65-.92-.65.1-.65.1-.65 1.1 0 1.73 1.1 1.73 1.1.92 1.65 2.57 1.2 3.21.92a2 2 0 01.64-1.47c-2.47-.27-5.04-1.19-5.04-5.5 0-1.1.46-2.1 1.2-2.84a3.76 3.76 0 010-2.93s.91-.28 3.11 1.1c1.8-.49 3.7-.49 5.5 0 2.1-1.38 3.02-1.1 3.02-1.1a3.76 3.76 0 010 2.93c.83.74 1.2 1.74 1.2 2.94 0 4.21-2.57 5.13-5.04 5.4.45.37.82.92.82 2.02v3.03c0 .27.1.64.73.55A11 11 0 0012 1.27"></path></svg></button></div></div></div></div><style data-emotion="css efwuvd">.css-efwuvd{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}@media (min-width:600px){.css-efwuvd{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:900px){.css-efwuvd{-webkit-flex-basis:66.666667%;-ms-flex-preferred-size:66.666667%;flex-basis:66.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:66.666667%;}}@media (min-width:1200px){.css-efwuvd{-webkit-flex-basis:66.666667%;-ms-flex-preferred-size:66.666667%;flex-basis:66.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:66.666667%;}}@media (min-width:1536px){.css-efwuvd{-webkit-flex-basis:66.666667%;-ms-flex-preferred-size:66.666667%;flex-basis:66.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:66.666667%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-12 MuiGrid-grid-md-8 css-efwuvd"><style data-emotion="css fbmkol">.css-fbmkol{-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-right:16px;}</style><div class="MuiBox-root css-fbmkol"><img src="/media/images/ml-inference-on-backend-vs-frontend-thumbnail.jpg" style="width:100%;max-width:75vw;height:auto;max-height:35vh;object-fit:cover"/></div></div></div><style data-emotion="css 8atqhb">.css-8atqhb{width:100%;}</style><div class="MuiBox-root css-8atqhb"><style data-emotion="css iv262p">.css-iv262p{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-16px;width:calc(100% + 16px);margin-left:-16px;margin-top:32px;margin-bottom:0px;}.css-iv262p>.MuiGrid-item{padding-top:16px;}.css-iv262p>.MuiGrid-item{padding-left:16px;}</style><div class="MuiGrid-root MuiGrid-container MuiGrid-spacing-xs-2 css-iv262p"><style data-emotion="css 1hclw6t">.css-1hclw6t{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;background:linear-gradient(to right, #eeeeee, #ffffff);border-radius:20px;}@media (min-width:600px){.css-1hclw6t{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:900px){.css-1hclw6t{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}@media (min-width:1200px){.css-1hclw6t{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1536px){.css-1hclw6t{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-12 MuiGrid-grid-md-4 MuiGrid-grid-lg-3 css-1hclw6t"><div class="MuiBox-root css-8atqhb"><style data-emotion="css 1zqdou">.css-1zqdou{width:100%;margin-bottom:16px;}@media (min-width:0px){.css-1zqdou{display:block;}}@media (min-width:900px){.css-1zqdou{display:none;}}</style><div class="MuiBox-root css-1zqdou"><style data-emotion="css mgu3mc">.css-mgu3mc{position:relative;-webkit-transition:margin 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:margin 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;overflow-anchor:none;border-radius:0;width:100%;margin-bottom:16px;box-shadow:0px 3px 3px -2px rgba(0,0,0,0.2),0px 3px 4px 0px rgba(0,0,0,0.14),0px 1px 8px 0px rgba(0,0,0,0.12);background-color:#ffffff22;}.css-mgu3mc::before{position:absolute;left:0;top:-1px;right:0;height:1px;content:"";opacity:1;background-color:rgba(0, 0, 0, 0.12);-webkit-transition:opacity 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:opacity 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;}.css-mgu3mc:first-of-type::before{display:none;}.css-mgu3mc.Mui-expanded::before{opacity:0;}.css-mgu3mc.Mui-expanded:first-of-type{margin-top:0;}.css-mgu3mc.Mui-expanded:last-of-type{margin-bottom:0;}.css-mgu3mc.Mui-expanded+.css-mgu3mc.Mui-expanded::before{display:none;}.css-mgu3mc.Mui-disabled{background-color:rgba(0, 0, 0, 0.12);}.css-mgu3mc:first-of-type{border-top-left-radius:4px;border-top-right-radius:4px;}.css-mgu3mc:last-of-type{border-bottom-left-radius:4px;border-bottom-right-radius:4px;}@supports (-ms-ime-align: auto){.css-mgu3mc:last-of-type{border-bottom-left-radius:0;border-bottom-right-radius:0;}}</style><style data-emotion="css 16ex79u">.css-16ex79u{background-color:#fff;color:rgba(0, 0, 0, 0.87);-webkit-transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;border-radius:4px;box-shadow:0px 2px 1px -1px rgba(0,0,0,0.2),0px 1px 1px 0px rgba(0,0,0,0.14),0px 1px 3px 0px rgba(0,0,0,0.12);position:relative;-webkit-transition:margin 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:margin 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;overflow-anchor:none;border-radius:0;width:100%;margin-bottom:16px;box-shadow:0px 3px 3px -2px rgba(0,0,0,0.2),0px 3px 4px 0px rgba(0,0,0,0.14),0px 1px 8px 0px rgba(0,0,0,0.12);background-color:#ffffff22;}.css-16ex79u::before{position:absolute;left:0;top:-1px;right:0;height:1px;content:"";opacity:1;background-color:rgba(0, 0, 0, 0.12);-webkit-transition:opacity 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:opacity 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;}.css-16ex79u:first-of-type::before{display:none;}.css-16ex79u.Mui-expanded::before{opacity:0;}.css-16ex79u.Mui-expanded:first-of-type{margin-top:0;}.css-16ex79u.Mui-expanded:last-of-type{margin-bottom:0;}.css-16ex79u.Mui-expanded+.css-16ex79u.Mui-expanded::before{display:none;}.css-16ex79u.Mui-disabled{background-color:rgba(0, 0, 0, 0.12);}.css-16ex79u:first-of-type{border-top-left-radius:4px;border-top-right-radius:4px;}.css-16ex79u:last-of-type{border-bottom-left-radius:4px;border-bottom-right-radius:4px;}@supports (-ms-ime-align: auto){.css-16ex79u:last-of-type{border-bottom-left-radius:0;border-bottom-right-radius:0;}}</style><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation1 MuiAccordion-root MuiAccordion-rounded css-16ex79u"><style data-emotion="css 148gpqp">.css-148gpqp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:48px;padding:0px 16px;-webkit-transition:min-height 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:min-height 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;}.css-148gpqp.Mui-focusVisible{background-color:rgba(0, 0, 0, 0.12);}.css-148gpqp.Mui-disabled{opacity:0.38;}.css-148gpqp:hover:not(.Mui-disabled){cursor:pointer;}</style><style data-emotion="css 1uaukoe">.css-1uaukoe{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:48px;padding:0px 16px;-webkit-transition:min-height 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:min-height 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;}.css-1uaukoe::-moz-focus-inner{border-style:none;}.css-1uaukoe.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-1uaukoe{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-1uaukoe.Mui-focusVisible{background-color:rgba(0, 0, 0, 0.12);}.css-1uaukoe.Mui-disabled{opacity:0.38;}.css-1uaukoe:hover:not(.Mui-disabled){cursor:pointer;}</style><div class="MuiButtonBase-root MuiAccordionSummary-root css-1uaukoe" tabindex="0" role="button" aria-expanded="false"><style data-emotion="css 1n11r91">.css-1n11r91{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;margin:12px 0;}</style><div class="MuiAccordionSummary-content css-1n11r91"><style data-emotion="css 10n6ggx">.css-10n6ggx{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:500;font-size:1.25rem;line-height:1.6;letter-spacing:0.0075em;margin:0px;padding:0px;}</style><h6 class="MuiTypography-root MuiTypography-h6 css-10n6ggx">Table of Contents</h6></div><style data-emotion="css 1fx8m19">.css-1fx8m19{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;color:rgba(0, 0, 0, 0.54);-webkit-transform:rotate(0deg);-moz-transform:rotate(0deg);-ms-transform:rotate(0deg);transform:rotate(0deg);-webkit-transition:-webkit-transform 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:transform 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;}.css-1fx8m19.Mui-expanded{-webkit-transform:rotate(180deg);-moz-transform:rotate(180deg);-ms-transform:rotate(180deg);transform:rotate(180deg);}</style><div class="MuiAccordionSummary-expandIconWrapper css-1fx8m19"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ExpandMoreIcon"><path d="M16.59 8.59 12 13.17 7.41 8.59 6 10l6 6 6-6z"></path></svg></div></div><style data-emotion="css a0y2e3">.css-a0y2e3{height:0;overflow:hidden;-webkit-transition:height 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:height 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;visibility:hidden;}</style><div class="MuiCollapse-root MuiCollapse-vertical MuiCollapse-hidden css-a0y2e3" style="min-height:0px"><style data-emotion="css hboir5">.css-hboir5{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;}</style><div class="MuiCollapse-wrapper MuiCollapse-vertical css-hboir5"><div class="MuiCollapse-wrapperInner MuiCollapse-vertical css-8atqhb"><div role="region" class="MuiAccordion-region"><style data-emotion="css 2m6k8o">.css-2m6k8o{padding:8px 16px 16px;width:90%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;margin-bottom:16px;}</style><div class="MuiAccordionDetails-root css-2m6k8o"><a href="#some-examples" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><style data-emotion="css vmnodn">.css-vmnodn{margin:0;margin-left:0px;margin-bottom:20px;}.css-vmnodn:hover{color:blue;}</style><p class="MuiTypography-root MuiTypography-p css-vmnodn">Some Examples</p></a><a href="#work-offline" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><style data-emotion="css 1i0m0sm">.css-1i0m0sm{margin:0;margin-left:8px;margin-bottom:16px;}.css-1i0m0sm:hover{color:blue;}</style><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Work Offline</p></a><a href="#user-data-privacy" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">User Data Privacy</p></a><a href="#speed" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Speed</p></a><a href="#privacy-the-other-way---keeping-the-model-a-secret" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Privacy the other way - keeping the Model a Secret</p></a><a href="#speed-2.0" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Speed 2.0</p></a><a href="#suitability-of-each-approach" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-vmnodn">Suitability of Each Approach</p></a><a href="#backend-side" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Backend Side</p></a><a href="#frontend-side" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Frontend Side</p></a><a href="#conclusion" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-vmnodn">Conclusion</p></a></div></div></div></div></div></div></div><style data-emotion="css 8e7o3j">.css-8e7o3j{width:100%;}@media (min-width:0px){.css-8e7o3j{display:none;}}@media (min-width:900px){.css-8e7o3j{display:block;}}</style><div class="MuiBox-root css-8e7o3j"><style data-emotion="css 1npmiby">.css-1npmiby{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1.5rem;line-height:1.334;letter-spacing:0em;margin:0px;padding:0px;}</style><h5 class="MuiTypography-root MuiTypography-h5 css-1npmiby">Table of Contents</h5><a href="#some-examples" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-vmnodn">Some Examples</p></a><a href="#work-offline" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Work Offline</p></a><a href="#user-data-privacy" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">User Data Privacy</p></a><a href="#speed" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Speed</p></a><a href="#privacy-the-other-way---keeping-the-model-a-secret" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Privacy the other way - keeping the Model a Secret</p></a><a href="#speed-2.0" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Speed 2.0</p></a><a href="#suitability-of-each-approach" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-vmnodn">Suitability of Each Approach</p></a><a href="#backend-side" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Backend Side</p></a><a href="#frontend-side" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-1i0m0sm">Frontend Side</p></a><a href="#conclusion" style="text-decoration:none;color:inherit;&amp;:visited:[object Object]"><p class="MuiTypography-root MuiTypography-p css-vmnodn">Conclusion</p></a></div></div></div><style data-emotion="css 4uwbp1">.css-4uwbp1{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;background:linear-gradient(to right, #ffffff, #eeeeee);border-radius:20px;}@media (min-width:600px){.css-4uwbp1{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:900px){.css-4uwbp1{-webkit-flex-basis:66.666667%;-ms-flex-preferred-size:66.666667%;flex-basis:66.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:66.666667%;}}@media (min-width:1200px){.css-4uwbp1{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:1536px){.css-4uwbp1{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-12 MuiGrid-grid-md-8 MuiGrid-grid-lg-9 css-4uwbp1"><style data-emotion="css 1zo2vp">.css-1zo2vp{-webkit-flex:1;-ms-flex:1;flex:1;margin-right:16px;}</style><div class="MuiBox-root css-1zo2vp"><style data-emotion="css vsuld9">.css-vsuld9{margin:0;text-align:justify;margin-bottom:16px;}</style><p class="MuiTypography-root MuiTypography-p css-vsuld9">When I built my first ML app back in early 2022 using a CNN in TensorFlow, I wondered what was the best way to get my friends to use this. Back then I had no money and could not afford a server in the cloud, so I decided to run my model in TensorFlow.js and package the app into some static files that could be served on GitHub. These days, I work with huge models as part of ML Ops, so we mostly keep our things on the server side. But is that always the right way? In this Article, we answer that exact question.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">To elaborate the comparison better, I&#x27;ll be considering some requirements and discussing how I would go about implementing them. If you would like to skip directly to the advantages and disadvantages of each approach, click <style data-emotion="css ct9vl7">.css-ct9vl7{-webkit-text-decoration:none;text-decoration:none;}.css-ct9vl7:hover{-webkit-text-decoration:underline;text-decoration:underline;}</style><style data-emotion="css 1vxruma">.css-1vxruma{margin:0;font:inherit;color:#1976d2;-webkit-text-decoration:none;text-decoration:none;}.css-1vxruma:hover{-webkit-text-decoration:underline;text-decoration:underline;}</style><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover css-1vxruma" href="#suitability-of-each-approach">right here</a>.</p><style data-emotion="css rg843f">.css-rg843f{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:2.125rem;line-height:1.235;letter-spacing:0.00735em;margin-bottom:16px;}</style><h1 class="MuiTypography-root MuiTypography-h4 css-rg843f" id="some-examples"><strong>Some Examples</strong></h1><p class="MuiTypography-root MuiTypography-p css-vsuld9">Let&#x27;s think of a few ML Ops use cases.</p><style data-emotion="css 1oj41as">.css-1oj41as{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1.5rem;line-height:1.334;letter-spacing:0em;margin-bottom:16px;}</style><h2 class="MuiTypography-root MuiTypography-h5 css-1oj41as" id="work-offline"><strong>Work Offline</strong></h2><p class="MuiTypography-root MuiTypography-p css-vsuld9">Last week I was interviewing someone and they described how their team built an app that was used by farmers in the alpine regions of Eastern India. The app took images from the phone&#x27;s camera, passed them to some transformer model, and displayed the output on screen. Due to the poor internet connectivity in these regions, the application had to be designed to work offline and the team knew from the start (a requirement in the SRS) that they could not host their model on a server and make API calls to it from the app. As a result, they had no option but to run inference on the Frontend which I believe they built using React Native (React or React Native ... it&#x27;s still the Frontend).</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">In such a case, there is no option but to have the model run locally.</p><h2 class="MuiTypography-root MuiTypography-h5 css-1oj41as" id="user-data-privacy"><strong>User Data Privacy</strong></h2><p class="MuiTypography-root MuiTypography-p css-vsuld9">Most of the time, you will have the choice to have your model on the server. But, the lack of internet connectivity is not the only issue. Say you have an app that allows users to enter their bank statements and tells them the best investments they could make, or maybe you&#x27;ve built an AI Photo Enhancer or something similar that can make a user&#x27;s images look better. In both of these cases, the data that the model takes as input is what the user would prefer to keep private. Your servers could have no data collection, and the application&#x27;s source code could be open source.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">But, as the layman user, I&#x27;m still sending my data to some servers, who knows whether or not they keep some of it?</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">The better option (the one that leaves no doubt in the user&#x27;s mind) is to not have anything sent to your servers and keep the user&#x27;s data on their device only. This necessitates that the inference is run locally.</p><h2 class="MuiTypography-root MuiTypography-h5 css-1oj41as" id="speed"><strong>Speed</strong></h2><p class="MuiTypography-root MuiTypography-p css-vsuld9">AI Photo Enhancers use single images as inputs and the result can be delivered after a couple of seconds. But what about something that needs to process video and do it in real-time (like that Instagram Hair Color Filter). Sending a request to the backend and getting a response 30 to 60 times every second is out of the question. The algorithm needs to run locally.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">Not only does the model have to be small (lower download size), it also has to be fast (run in real-time on the phone&#x27;s GPU).</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">Sure, you could get much faster inference on a Nvidia A100 Server that crunches floating point operations like there&#x27;s no tomorrow, but you would still have to send 30 images to the server every second. The latency induced by the requests is much greater than the gain from putting the model on the server.</p><h2 class="MuiTypography-root MuiTypography-h5 css-1oj41as" id="privacy-the-other-way---keeping-the-model-a-secret"><strong>Privacy the other way - keeping the Model a Secret</strong></h2><p class="MuiTypography-root MuiTypography-p css-vsuld9">We&#x27;ve talked about User Privacy but what about the company&#x27;s privacy? If you have a state-of-the-art model that nobody in the world can replicate, or if you have a paid subscription for users to use your model, you probably don&#x27;t wanna put it on the client side from where anyone can access the model&#x27;s architecture or weights. Code can be obfuscated and applications can be compiled into binaries, but neither of these is gonna stop a determined pirate with the right tools from getting to your model. If you wanna keep it safe, not having it on the client side is the way to go.</p><h2 class="MuiTypography-root MuiTypography-h5 css-1oj41as" id="speed-2.0"><strong>Speed 2.0</strong></h2><p class="MuiTypography-root MuiTypography-p css-vsuld9">While small models running locally can provide inference in real-time, this is not true for bigger models. As the model&#x27;s size increases you need faster and faster hardware to run it in a decent amount of time. The hardware available on the client side may not be enough. So it makes much more sense to have the model on a server somewhere running on the best GPU. A single server could serve multiple devices and each user will get the response in a few milliseconds.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">And it gets better. If the server receives many requests every second, it can put two or more requests from different users into the same batch and then pass that batch to the model. GPUs are efficient at parallel processing and batched inference allows us to make the most out of it. In <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover css-1vxruma" href="/ml-ops/gpu-vs-cpu-performance-for-ml-inference-workflows">this Post</a>, I show how the inference time decreases with large batch sizes and their effect on GPU memory consumption, check it out for more info.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">Finally, the user cannot be expected to download a 4 GB model to run the application. So, for very large models, it makes much more sense to have them on the server side.</p><h1 class="MuiTypography-root MuiTypography-h4 css-rg843f" id="suitability-of-each-approach"><strong>Suitability of Each Approach</strong></h1><p class="MuiTypography-root MuiTypography-p css-vsuld9">We&#x27;ve seen how either approach allows us some capabilities that the other does not. Below, we&#x27;ve summarized the advantages of both methods.</p><h2 class="MuiTypography-root MuiTypography-h5 css-1oj41as" id="backend-side"><strong>Backend Side</strong></h2><p class="MuiTypography-root MuiTypography-p css-vsuld9">1) Model architecture and weights remain private (especially useful if you have a state-of-the-art product or are running a paid service)</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">1) Large models (could be a few gigabytes) are difficult to download on the Frontend so server-side inference is the more convenient option.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">1) Inference speeds will be identical across devices since the model runs in the Cloud on perhaps the best GPU.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">1) If the process involves making multiple database calls, contacting other APIs or microservices, and running multiple inference sessions - it&#x27;s probably best to keep this on the server side.</p><h2 class="MuiTypography-root MuiTypography-h5 css-1oj41as" id="frontend-side"><strong>Frontend Side</strong></h2><p class="MuiTypography-root MuiTypography-p css-vsuld9">1) User Data remains protected - it&#x27;s not sent to a server.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">1) Hosting of the system becomes a lot easier since we only have to serve static files for the Frontend.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">1) No latency in communicating with the backend - leads to faster inference for smaller models and allows for live processing.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">1) Inference will work offline.</p><h1 class="MuiTypography-root MuiTypography-h4 css-rg843f" id="conclusion"><strong>Conclusion</strong></h1><p class="MuiTypography-root MuiTypography-p css-vsuld9">So, which is it then: Backend or Frontend? Well, like most problems in Software Engineering, there is no right answer, there are only trade-offs. AS we&#x27;ve seen, ML models on the server side or the client side both have their own benefits and it&#x27;s up to you to choose the way that suits your application the best.</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">Once you&#x27;ve chosen the right way to deploy your model, you will be looking for how to do it. In the Blog Posts listed below, I deploy the same model (a simple CNN) in 6 different ways. Pick the method of your choice and Read On!</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">1) On Backend:</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">a) <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover css-1vxruma" href="/ml-ops/fastapi-torch-backend">Python: Flask and Torch</a></p><p class="MuiTypography-root MuiTypography-p css-vsuld9">b) <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover css-1vxruma" href="/ml-ops/fastapi-tensorflow-backend">Python: Flask and TensorFlow</a></p><p class="MuiTypography-root MuiTypography-p css-vsuld9">c) <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover css-1vxruma" href="/ml-ops/fastapi-onnx-backend">Python: Flask and ONNX</a></p><p class="MuiTypography-root MuiTypography-p css-vsuld9">d) <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover css-1vxruma" href="/ml-ops/node-express-onnx-backend">Node.js: Express and ONNX</a></p><p class="MuiTypography-root MuiTypography-p css-vsuld9">2) On Frontend:</p><p class="MuiTypography-root MuiTypography-p css-vsuld9">a) <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover css-1vxruma" href="/ml-ops/onnxruntime-web-inference-in-react">React and ONNX</a></p><p class="MuiTypography-root MuiTypography-p css-vsuld9">b) <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover css-1vxruma" href="/ml-ops/tensorflow-js-inference-in-react">React and TensorFlow.js</a></p><p class="MuiTypography-root MuiTypography-p css-vsuld9">See you next time :)</p></div></div></div></div><style data-emotion="css sdeu8y">.css-sdeu8y{margin-top:40px;margin-bottom:40px;padding-bottom:16px;width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="MuiBox-root css-sdeu8y"><style data-emotion="css iyxjf1">.css-iyxjf1{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-16px;width:calc(100% + 16px);margin-left:-16px;margin-top:32px;margin-bottom:32px;}.css-iyxjf1>.MuiGrid-item{padding-top:16px;}.css-iyxjf1>.MuiGrid-item{padding-left:16px;}</style><div class="MuiGrid-root MuiGrid-container MuiGrid-spacing-xs-2 css-iyxjf1"><style data-emotion="css 1etv89n">.css-1etv89n{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}@media (min-width:600px){.css-1etv89n{-webkit-flex-basis:50%;-ms-flex-preferred-size:50%;flex-basis:50%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:50%;}}@media (min-width:900px){.css-1etv89n{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}@media (min-width:1200px){.css-1etv89n{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1536px){.css-1etv89n{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-6 MuiGrid-grid-md-4 MuiGrid-grid-lg-3 css-1etv89n"><a style="text-decoration:none" href="/ml-ops/gpu-vs-cpu-performance-for-ml-inference-workflows/"><style data-emotion="css 1dp4q5j">.css-1dp4q5j{overflow:hidden;width:100%;height:100%;box-shadow:1px 1px 1px 1px "#eeeeee";}.css-1dp4q5j:hover{box-shadow:3px 3px 3px 3px "#eeeeee";cursor:pointer;}</style><style data-emotion="css ewbf0o">.css-ewbf0o{background-color:#fff;color:rgba(0, 0, 0, 0.87);-webkit-transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:box-shadow 300ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;border-radius:4px;box-shadow:0px 2px 1px -1px rgba(0,0,0,0.2),0px 1px 1px 0px rgba(0,0,0,0.14),0px 1px 3px 0px rgba(0,0,0,0.12);overflow:hidden;width:100%;height:100%;box-shadow:1px 1px 1px 1px "#eeeeee";}.css-ewbf0o:hover{box-shadow:3px 3px 3px 3px "#eeeeee";cursor:pointer;}</style><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation1 MuiCard-root css-ewbf0o"><style data-emotion="css 146e5oc">.css-146e5oc{display:block;-webkit-background-size:cover;background-size:cover;background-repeat:no-repeat;-webkit-background-position:center;background-position:center;width:100%;object-fit:cover;object-fit:cover;}</style><img class="MuiCardMedia-root MuiCardMedia-media MuiCardMedia-img css-146e5oc" src="/media/images/gpu-vs-cpu-performance-for-ml-inference-workflows-thumbnail.jpg" height="150" alt="ML Inference Performance on GPU and CPU across different batch sizes."/><style data-emotion="css 1qw96cp">.css-1qw96cp{padding:16px;}.css-1qw96cp:last-child{padding-bottom:24px;}</style><div class="MuiCardContent-root css-1qw96cp"><style data-emotion="css 4an0mh">.css-4an0mh{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:500;font-size:1.25rem;line-height:1.6;letter-spacing:0.0075em;margin-bottom:0.35em;}</style><h2 class="MuiTypography-root MuiTypography-h6 MuiTypography-gutterBottom css-4an0mh"> <!-- -->ML Inference Performance on GPU and CPU across different batch sizes.</h2><style data-emotion="css r1ev5b">.css-r1ev5b{margin:0;margin-bottom:0.35em;overflow:hidden;text-overflow:ellipsis;display:-webkit-box;-webkit-line-clamp:3;-webkit-box-orient:vertical;}</style><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-r1ev5b">A comparison of ML inference speed and memory consumption across various batch sizes on both GPU and CPU.</p><style data-emotion="css 4jg4rq">.css-4jg4rq{width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="MuiBox-root css-4jg4rq"><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-mxjm1x">08m Read</p></div></div></div></a></div><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-6 MuiGrid-grid-md-4 MuiGrid-grid-lg-3 css-1etv89n"><a style="text-decoration:none" href="/ml-ops/fastapi-onnx-backend/"><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation1 MuiCard-root css-ewbf0o"><img class="MuiCardMedia-root MuiCardMedia-media MuiCardMedia-img css-146e5oc" src="/media/images/fastapi-onnx-backend-thumbnail.jpg" height="150" alt="Serving an ONNX Model using FastAPI"/><div class="MuiCardContent-root css-1qw96cp"><h2 class="MuiTypography-root MuiTypography-h6 MuiTypography-gutterBottom css-4an0mh"> <!-- -->Serving an ONNX Model using FastAPI</h2><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-r1ev5b">Learn how to serve an ONNX model with FastAPI.</p><div class="MuiBox-root css-4jg4rq"><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-mxjm1x">06m Read</p></div></div></div></a></div><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-6 MuiGrid-grid-md-4 MuiGrid-grid-lg-3 css-1etv89n"><a style="text-decoration:none" href="/ml-ops/node-express-onnx-backend/"><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation1 MuiCard-root css-ewbf0o"><img class="MuiCardMedia-root MuiCardMedia-media MuiCardMedia-img css-146e5oc" src="/media/images/node-express-onnx-backend-thumbnail.jpg" height="150" alt="Express.js API for Inference using an ONNX Model"/><div class="MuiCardContent-root css-1qw96cp"><h2 class="MuiTypography-root MuiTypography-h6 MuiTypography-gutterBottom css-4an0mh"> <!-- -->Express.js API for Inference using an ONNX Model</h2><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-r1ev5b">Deploying an ONNX Model using Express.js.</p><div class="MuiBox-root css-4jg4rq"><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-mxjm1x">08m Read</p></div></div></div></a></div><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-6 MuiGrid-grid-md-4 MuiGrid-grid-lg-3 css-1etv89n"><a style="text-decoration:none" href="/ml-ops/onnxruntime-web-inference-in-react/"><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation1 MuiCard-root css-ewbf0o"><img class="MuiCardMedia-root MuiCardMedia-media MuiCardMedia-img css-146e5oc" src="/media/images/react-digit-recog-app-final.jpg" height="150" alt="ONNXRuntime Inference in a React App"/><div class="MuiCardContent-root css-1qw96cp"><h2 class="MuiTypography-root MuiTypography-h6 MuiTypography-gutterBottom css-4an0mh"> <!-- -->ONNXRuntime Inference in a React App</h2><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-r1ev5b">Inferencing on an ONNX model in a React App using ONNXRuntime Web.</p><div class="MuiBox-root css-4jg4rq"><p class="MuiTypography-root MuiTypography-p MuiTypography-gutterBottom css-mxjm1x">08m Read</p></div></div></div></a></div></div></div></div><footer style="margin-top:25px"><style data-emotion="css 1uy1rgq">.css-1uy1rgq{width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;padding-top:200px;border-top:1px solid black;}</style><div class="MuiBox-root css-1uy1rgq"><img src="/media/images/main-contact-email-light.jpg" style="width:250px;height:27px"/><style data-emotion="css 1uk1gs8">.css-1uk1gs8{margin:0;}</style><span class="MuiTypography-root MuiTypography-p css-1uk1gs8">We typically reply within 24 hours.</span><style data-emotion="css zq6grw">.css-zq6grw{margin:0;font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1.5rem;line-height:1.334;letter-spacing:0em;}</style><h5 class="MuiTypography-root MuiTypography-h5 css-zq6grw"> 2024 <!-- -->A Nice Teacher</h5></div></footer></div><script src="/_next/static/chunks/webpack-83486951edee0db5.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/1d4d01086947be98.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n5:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[6871,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"271\",\"static/chunks/271-37a22bace913f735.js\",\"185\",\"static/chunks/app/layout-08611f287dda1230.js\"],\"default\"]\na:I[5877,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"271\",\"static/chunks/271-37a22bace913f735.js\",\"185\",\"static/chunks/app/layout-08611f287dda1230.js\"],\"default\"]\nb:I[902,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"271\",\"static/chunks/271-37a22bace913f735.js\",\"185\",\"static/chunks/app/layout-08611f287dda1230.js\"],\"\"]\nc:I[5218,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\nd:I[2324,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"default\"]\ne:I[2591,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\nf:I[231,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\n10:I[3180,[\"98\",\"static/c"])</script><script>self.__next_f.push([1,"hunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\n11:I[3245,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"271\",\"static/chunks/271-37a22bace913f735.js\",\"185\",\"static/chunks/app/layout-08611f287dda1230.js\"],\"default\"]\n13:I[6130,[],\"\"]\n6:[\"categorySlug\",\"ml-ops\",\"d\"]\n7:[\"postOrSeriesSlug\",\"ml-inference-on-backend-vs-frontend\",\"d\"]\n14:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1d4d01086947be98.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"VvaX91qL0y6klITKNgfgL\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/ml-ops/ml-inference-on-backend-vs-frontend/\",\"initialTree\":[\"\",{\"children\":[[\"categorySlug\",\"ml-ops\",\"d\"],{\"children\":[[\"postOrSeriesSlug\",\"ml-inference-on-backend-vs-frontend\",\"d\"],{\"children\":[\"__PAGE__?{\\\"categorySlug\\\":\\\"ml-ops\\\",\\\"postOrSeriesSlug\\\":\\\"ml-inference-on-backend-vs-frontend\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"categorySlug\",\"ml-ops\",\"d\"],{\"children\":[[\"postOrSeriesSlug\",\"ml-inference-on-backend-vs-frontend\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$6\",\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$6\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"__className_d65c78\",\"children\":[\"$\",\"$L9\",null,{\"children\":[[\"$\",\"$La\",null,{}],[\"$\",\"$Lb\",null,{\"maxWidth\":\"lg\",\"children\":[[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"$Lc\",null,{\"children\":[[\"$\",\"$Ld\",null,{\"render\":false,\"targetSiteNavigationState\":[],\"targetPageNavigationState\":[]}],[\"$\",\"$Le\",null,{\"variant\":\"h4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Not Found\"}]}],[\"$\",\"$Le\",null,{\"variant\":\"h6\",\"mb\":3,\"children\":\"Oops! It looks like the page you're looking for does not exist.\"}],[\"$\",\"$Lf\",null,{\"href\":\"/\",\"children\":[\"$\",\"$L10\",null,{\"variant\":\"contained\",\"sx\":{\"marginRight\":5,\"marginBottom\":1},\"children\":\"Take me Home\"}]}]]}],\"notFoundStyles\":[],\"styles\":null}],[\"$\",\"$L11\",null,{}]]}]]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$L12\"],\"globalErrorComponent\":\"$13\",\"missingSlots\":\"$W14\"}]]\n"])</script><script>self.__next_f.push([1,"12:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n3:null\n"])</script><script>self.__next_f.push([1,"15:I[3507,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\n17:I[4204,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"default\"]\n18:I[1847,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"default\"]\n19:I[8125,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\n1a:I[3578,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"default\"]\n1b:I[7005,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"$Lc\",null,{\"mb\":5,\"pb\":2,\"sx\":{\"width\":\"100%\",\"display\":\"flex\",\"flexDirection\":\"column\",\"justifyContent\":\"flex-start\",\"alignItems\":\"flex-start\"},\"children\":[[\"$\",\"$Ld\",null,{\"render\":true,\"targetSiteNavigationState\":[{\"absoluteSlug\":\"/ml-ops\",\"title\":\"ML Ops\"},{\"absoluteSlug\":\"/ml-ops/ml-inference-on-backend-vs-frontend\",\"title\":\"ML Inference on Backend vs Frontend\"}],\"targetPageNavigationState\":[{\"title\":\"Some Examples\",\"absoluteSlug\":\"#some-examples\"},{\"title\":\"Work Offline\",\"absoluteSlug\":\"#work-offline\"},{\"title\":\"User Data Privacy\",\"absoluteSlug\":\"#user-data-privacy\"},{\"title\":\"Speed\",\"absoluteSlug\":\"#speed\"},{\"title\":\"Privacy the other way - keeping the Model a Secret\",\"absoluteSlug\":\"#privacy-the-other-way---keeping-the-model-a-secret\"},{\"title\":\"Speed 2.0\",\"absoluteSlug\":\"#speed-2.0\"},{\"title\":\"Suitability of Each Approach\",\"absoluteSlug\":\"#suitability-of-each-approach\"},{\"title\":\"Backend Side\",\"absoluteSlug\":\"#backend-side\"},{\"title\":\"Frontend Side\",\"absoluteSlug\":\"#frontend-side\"},{\"title\":\"Conclusion\",\"absoluteSlug\":\"#conclusion\"}]}],[\"$\",\"$L15\",null,{\"container\":true,\"spacing\":2,\"mb\":0,\"children\":[[\"$\",\"$L15\",null,{\"item\":true,\"xs\":12,\"sm\":12,\"md\":4,\"sx\":{\"background\":\"linear-gradient(to right, #eeeeee, #ffffff)\",\"borderRadius\":5},\"children\":[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\",\"height\":\"100%\",\"display\":\"flex\",\"flexDirection\":\"column\",\"justifyContent\":\"center\",\"alignItems\":\"flex-start\",\"paddingBottom\":2},\"children\":[[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"h5\",\"component\":\"h1\",\"children\":\"ML Inference on Backend vs Frontend\"}],[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"mb\":4,\"children\":\"A comparison of ML inference speed and memory consumption across various batch sizes on both GPU and CPU.\"}],[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\",\"display\":\"flex\",\"flexDirection\":\"row\",\"justifyContent\":\"space-between\",\"alignItems\":\"center\",\"marginBottom\":2},\"children\":[[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"children\":\"June 17, 2024\"}],[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"children\":[\"05m\",\" Read\"]}]]}],\"$L16\",false]}]}],[\"$\",\"$L15\",null,{\"item\":true,\"xs\":12,\"sm\":12,\"md\":8,\"children\":[\"$\",\"$Lc\",null,{\"sx\":{\"flex\":1,\"display\":\"flex\",\"flexDirection\":\"column\",\"justifyContent\":\"center\",\"alignItems\":\"center\",\"marginRight\":2},\"children\":[\"$\",\"img\",null,{\"src\":\"/media/images/ml-inference-on-backend-vs-frontend-thumbnail.jpg\",\"style\":{\"width\":\"100%\",\"maxWidth\":\"75vw\",\"height\":\"auto\",\"maxHeight\":\"35vh\",\"objectFit\":\"cover\"}}]}]}]]}],[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\"},\"children\":[\"$\",\"$L15\",null,{\"container\":true,\"spacing\":2,\"mt\":4,\"mb\":0,\"children\":[[\"$\",\"$L15\",null,{\"item\":true,\"xs\":12,\"sm\":12,\"md\":4,\"lg\":3,\"sx\":{\"background\":\"linear-gradient(to right, #eeeeee, #ffffff)\",\"borderRadius\":5},\"children\":[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\"},\"children\":[[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\",\"display\":{\"xs\":\"block\",\"md\":\"none\"},\"marginBottom\":2},\"children\":[\"$\",\"$L17\",null,{\"sx\":{\"width\":\"100%\",\"marginBottom\":2,\"boxShadow\":3,\"backgroundColor\":\"#ffffff22\"},\"disableGutters\":true,\"children\":[[\"$\",\"$L18\",null,{\"expandIcon\":[\"$\",\"$L19\",null,{}],\"children\":[\"$\",\"$Le\",null,{\"variant\":\"h6\",\"component\":\"h6\",\"sx\":{\"margin\":0,\"padding\":0},\"children\":\"Table of Contents\"}]}],[\"$\",\"$L1a\",null,{\"sx\":{\"width\":\"90%\",\"display\":\"flex\",\"flexDirection\":\"column\",\"justifyContent\":\"flex-start\",\"alignItems\":\"flex-start\",\"marginBottom\":2},\"children\":[[\"$\",\"a\",\"0\",{\"href\":\"#some-examples\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"0\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":0,\"mb\":2.5,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Some Examples\"}]}],[\"$\",\"a\",\"1\",{\"href\":\"#work-offline\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"1\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Work Offline\"}]}],[\"$\",\"a\",\"2\",{\"href\":\"#user-data-privacy\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"2\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"User Data Privacy\"}]}],[\"$\",\"a\",\"3\",{\"href\":\"#speed\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"3\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Speed\"}]}],[\"$\",\"a\",\"4\",{\"href\":\"#privacy-the-other-way---keeping-the-model-a-secret\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"4\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Privacy the other way - keeping the Model a Secret\"}]}],[\"$\",\"a\",\"5\",{\"href\":\"#speed-2.0\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"5\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Speed 2.0\"}]}],[\"$\",\"a\",\"6\",{\"href\":\"#suitability-of-each-approach\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"6\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":0,\"mb\":2.5,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Suitability of Each Approach\"}]}],[\"$\",\"a\",\"7\",{\"href\":\"#backend-side\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"7\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Backend Side\"}]}],[\"$\",\"a\",\"8\",{\"href\":\"#frontend-side\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"8\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Frontend Side\"}]}],[\"$\",\"a\",\"9\",{\"href\":\"#conclusion\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"9\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":0,\"mb\":2.5,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Conclusion\"}]}]]}]]}]}],[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\",\"display\":{\"xs\":\"none\",\"md\":\"block\"}},\"children\":[[\"$\",\"$Le\",null,{\"variant\":\"h5\",\"component\":\"h5\",\"sx\":{\"margin\":0,\"padding\":0},\"children\":\"Table of Contents\"}],[[\"$\",\"a\",\"0\",{\"href\":\"#some-examples\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"0\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":0,\"mb\":2.5,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Some Examples\"}]}],[\"$\",\"a\",\"1\",{\"href\":\"#work-offline\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"1\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Work Offline\"}]}],[\"$\",\"a\",\"2\",{\"href\":\"#user-data-privacy\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"2\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"User Data Privacy\"}]}],[\"$\",\"a\",\"3\",{\"href\":\"#speed\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"3\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Speed\"}]}],[\"$\",\"a\",\"4\",{\"href\":\"#privacy-the-other-way---keeping-the-model-a-secret\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"4\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Privacy the other way - keeping the Model a Secret\"}]}],[\"$\",\"a\",\"5\",{\"href\":\"#speed-2.0\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"5\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Speed 2.0\"}]}],[\"$\",\"a\",\"6\",{\"href\":\"#suitability-of-each-approach\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"6\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":0,\"mb\":2.5,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Suitability of Each Approach\"}]}],[\"$\",\"a\",\"7\",{\"href\":\"#backend-side\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"7\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Backend Side\"}]}],[\"$\",\"a\",\"8\",{\"href\":\"#frontend-side\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"8\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":1,\"mb\":2,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Frontend Side\"}]}],[\"$\",\"a\",\"9\",{\"href\":\"#conclusion\",\"style\":{\"textDecoration\":\"none\",\"color\":\"inherit\",\"\u0026:visited\":{\"textDecoration\":\"none\",\"color\":\"inherit\"}},\"children\":[\"$\",\"$Le\",\"9\",{\"variant\":\"p\",\"component\":\"p\",\"ml\":0,\"mb\":2.5,\"sx\":{\"\u0026:hover\":{\"color\":\"blue\"}},\"children\":\"Conclusion\"}]}]]]}]]}]}],[\"$\",\"$L15\",null,{\"item\":true,\"xs\":12,\"sm\":12,\"md\":8,\"lg\":9,\"sx\":{\"background\":\"linear-gradient(to right, #ffffff, #eeeeee)\",\"borderRadius\":5},\"children\":[\"$\",\"$Lc\",null,{\"sx\":{\"flex\":1,\"marginRight\":2},\"children\":[[\"$\",\"$Le\",\"0\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"When I built my first ML app back in early 2022 using a CNN in TensorFlow, I wondered what was the best way to get my friends to use this. Back then I had no money and could not afford a server in the cloud, so I decided to run my model in TensorFlow.js and package the app into some static files that could be served on GitHub. These days, I work with huge models as part of ML Ops, so we mostly keep our things on the server side. But is that always the right way? In this Article, we answer that exact question.\"]}],[\"$\",\"$Le\",\"1\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"To elaborate the comparison better, I'll be considering some requirements and discussing how I would go about implementing them. If you would like to skip directly to the advantages and disadvantages of each approach, click \",[\"$\",\"$L1b\",\"1-link\",{\"href\":\"#suitability-of-each-approach\",\"color\":\"primary\",\"underline\":\"hover\",\"children\":\"right here\"}],\".\"]}],[\"$\",\"$Le\",\"2\",{\"id\":\"some-examples\",\"variant\":\"h4\",\"component\":\"h1\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"Some Examples\"}]}],[\"$\",\"$Le\",\"3\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"Let's think of a few ML Ops use cases.\"]}],[\"$\",\"$Le\",\"4\",{\"id\":\"work-offline\",\"variant\":\"h5\",\"component\":\"h2\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"Work Offline\"}]}],[\"$\",\"$Le\",\"5\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"Last week I was interviewing someone and they described how their team built an app that was used by farmers in the alpine regions of Eastern India. The app took images from the phone's camera, passed them to some transformer model, and displayed the output on screen. Due to the poor internet connectivity in these regions, the application had to be designed to work offline and the team knew from the start (a requirement in the SRS) that they could not host their model on a server and make API calls to it from the app. As a result, they had no option but to run inference on the Frontend which I believe they built using React Native (React or React Native ... it's still the Frontend).\"]}],[\"$\",\"$Le\",\"6\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"In such a case, there is no option but to have the model run locally.\"]}],[\"$\",\"$Le\",\"7\",{\"id\":\"user-data-privacy\",\"variant\":\"h5\",\"component\":\"h2\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"User Data Privacy\"}]}],[\"$\",\"$Le\",\"8\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"Most of the time, you will have the choice to have your model on the server. But, the lack of internet connectivity is not the only issue. Say you have an app that allows users to enter their bank statements and tells them the best investments they could make, or maybe you've built an AI Photo Enhancer or something similar that can make a user's images look better. In both of these cases, the data that the model takes as input is what the user would prefer to keep private. Your servers could have no data collection, and the application's source code could be open source.\"]}],[\"$\",\"$Le\",\"9\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"But, as the layman user, I'm still sending my data to some servers, who knows whether or not they keep some of it?\"]}],[\"$\",\"$Le\",\"10\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"The better option (the one that leaves no doubt in the user's mind) is to not have anything sent to your servers and keep the user's data on their device only. This necessitates that the inference is run locally.\"]}],[\"$\",\"$Le\",\"11\",{\"id\":\"speed\",\"variant\":\"h5\",\"component\":\"h2\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"Speed\"}]}],[\"$\",\"$Le\",\"12\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"AI Photo Enhancers use single images as inputs and the result can be delivered after a couple of seconds. But what about something that needs to process video and do it in real-time (like that Instagram Hair Color Filter). Sending a request to the backend and getting a response 30 to 60 times every second is out of the question. The algorithm needs to run locally.\"]}],[\"$\",\"$Le\",\"13\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"Not only does the model have to be small (lower download size), it also has to be fast (run in real-time on the phone's GPU).\"]}],[\"$\",\"$Le\",\"14\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"Sure, you could get much faster inference on a Nvidia A100 Server that crunches floating point operations like there's no tomorrow, but you would still have to send 30 images to the server every second. The latency induced by the requests is much greater than the gain from putting the model on the server.\"]}],[\"$\",\"$Le\",\"15\",{\"id\":\"privacy-the-other-way---keeping-the-model-a-secret\",\"variant\":\"h5\",\"component\":\"h2\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"Privacy the other way - keeping the Model a Secret\"}]}],[\"$\",\"$Le\",\"16\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"We've talked about User Privacy but what about the company's privacy? If you have a state-of-the-art model that nobody in the world can replicate, or if you have a paid subscription for users to use your model, you probably don't wanna put it on the client side from where anyone can access the model's architecture or weights. Code can be obfuscated and applications can be compiled into binaries, but neither of these is gonna stop a determined pirate with the right tools from getting to your model. If you wanna keep it safe, not having it on the client side is the way to go.\"]}],[\"$\",\"$Le\",\"17\",{\"id\":\"speed-2.0\",\"variant\":\"h5\",\"component\":\"h2\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"Speed 2.0\"}]}],[\"$\",\"$Le\",\"18\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"While small models running locally can provide inference in real-time, this is not true for bigger models. As the model's size increases you need faster and faster hardware to run it in a decent amount of time. The hardware available on the client side may not be enough. So it makes much more sense to have the model on a server somewhere running on the best GPU. A single server could serve multiple devices and each user will get the response in a few milliseconds.\"]}],[\"$\",\"$Le\",\"19\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"And it gets better. If the server receives many requests every second, it can put two or more requests from different users into the same batch and then pass that batch to the model. GPUs are efficient at parallel processing and batched inference allows us to make the most out of it. In \",[\"$\",\"$L1b\",\"19-link\",{\"href\":\"/ml-ops/gpu-vs-cpu-performance-for-ml-inference-workflows\",\"color\":\"primary\",\"underline\":\"hover\",\"children\":\"this Post\"}],\", I show how the inference time decreases with large batch sizes and their effect on GPU memory consumption, check it out for more info.\"]}],[\"$\",\"$Le\",\"20\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"Finally, the user cannot be expected to download a 4 GB model to run the application. So, for very large models, it makes much more sense to have them on the server side.\"]}],[\"$\",\"$Le\",\"21\",{\"id\":\"suitability-of-each-approach\",\"variant\":\"h4\",\"component\":\"h1\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"Suitability of Each Approach\"}]}],[\"$\",\"$Le\",\"22\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"We've seen how either approach allows us some capabilities that the other does not. Below, we've summarized the advantages of both methods.\"]}],[\"$\",\"$Le\",\"23\",{\"id\":\"backend-side\",\"variant\":\"h5\",\"component\":\"h2\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"Backend Side\"}]}],[\"$\",\"$Le\",\"24\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"1) Model architecture and weights remain private (especially useful if you have a state-of-the-art product or are running a paid service)\"]}],[\"$\",\"$Le\",\"25\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"1) Large models (could be a few gigabytes) are difficult to download on the Frontend so server-side inference is the more convenient option.\"]}],[\"$\",\"$Le\",\"26\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"1) Inference speeds will be identical across devices since the model runs in the Cloud on perhaps the best GPU.\"]}],[\"$\",\"$Le\",\"27\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"1) If the process involves making multiple database calls, contacting other APIs or microservices, and running multiple inference sessions - it's probably best to keep this on the server side.\"]}],[\"$\",\"$Le\",\"28\",{\"id\":\"frontend-side\",\"variant\":\"h5\",\"component\":\"h2\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"Frontend Side\"}]}],[\"$\",\"$Le\",\"29\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"1) User Data remains protected - it's not sent to a server.\"]}],[\"$\",\"$Le\",\"30\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"1) Hosting of the system becomes a lot easier since we only have to serve static files for the Frontend.\"]}],[\"$\",\"$Le\",\"31\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"1) No latency in communicating with the backend - leads to faster inference for smaller models and allows for live processing.\"]}],[\"$\",\"$Le\",\"32\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"1) Inference will work offline.\"]}],[\"$\",\"$Le\",\"33\",{\"id\":\"conclusion\",\"variant\":\"h4\",\"component\":\"h1\",\"mb\":2,\"children\":[\"$\",\"strong\",null,{\"children\":\"Conclusion\"}]}],[\"$\",\"$Le\",\"34\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"So, which is it then: Backend or Frontend? Well, like most problems in Software Engineering, there is no right answer, there are only trade-offs. AS we've seen, ML models on the server side or the client side both have their own benefits and it's up to you to choose the way that suits your application the best.\"]}],[\"$\",\"$Le\",\"35\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"Once you've chosen the right way to deploy your model, you will be looking for how to do it. In the Blog Posts listed below, I deploy the same model (a simple CNN) in 6 different ways. Pick the method of your choice and Read On!\"]}],[\"$\",\"$Le\",\"36\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"1) On Backend:\"]}],[\"$\",\"$Le\",\"37\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"a) \",[\"$\",\"$L1b\",\"37-link\",{\"href\":\"/ml-ops/fastapi-torch-backend\",\"color\":\"primary\",\"underline\":\"hover\",\"children\":\"Python: Flask and Torch\"}],\"\"]}],[\"$\",\"$Le\",\"38\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"b) \",[\"$\",\"$L1b\",\"38-link\",{\"href\":\"/ml-ops/fastapi-tensorflow-backend\",\"color\":\"primary\",\"underline\":\"hover\",\"children\":\"Python: Flask and TensorFlow\"}],\"\"]}],[\"$\",\"$Le\",\"39\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"c) \",[\"$\",\"$L1b\",\"39-link\",{\"href\":\"/ml-ops/fastapi-onnx-backend\",\"color\":\"primary\",\"underline\":\"hover\",\"children\":\"Python: Flask and ONNX\"}],\"\"]}],[\"$\",\"$Le\",\"40\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"d) \",[\"$\",\"$L1b\",\"40-link\",{\"href\":\"/ml-ops/node-express-onnx-backend\",\"color\":\"primary\",\"underline\":\"hover\",\"children\":\"Node.js: Express and ONNX\"}],\"\"]}],[\"$\",\"$Le\",\"41\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"2) On Frontend:\"]}],[\"$\",\"$Le\",\"42\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"a) \",[\"$\",\"$L1b\",\"42-link\",{\"href\":\"/ml-ops/onnxruntime-web-inference-in-react\",\"color\":\"primary\",\"underline\":\"hover\",\"children\":\"React and ONNX\"}],\"\"]}],[\"$\",\"$Le\",\"43\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"b) \",[\"$\",\"$L1b\",\"43-link\",{\"href\":\"/ml-ops/tensorflow-js-inference-in-react\",\"color\":\"primary\",\"underline\":\"hover\",\"children\":\"React and TensorFlow.js\"}],\"\"]}],[\"$\",\"$Le\",\"44\",{\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"textAlign\":\"justify\",\"marginBottom\":2},\"children\":[\"$undefined\",\"See you next time :)\"]}]]}]}]]}]}],\"$L1c\"]}]\n"])</script><script>self.__next_f.push([1,"1d:I[3713,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"default\"]\n16:[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\",\"display\":\"flex\",\"flexDirection\":\"row\",\"justifyContent\":\"space-between\",\"alignItems\":\"center\"},\"children\":[[\"$\",\"$Le\",null,{\"variant\":\"p\",\"component\":\"p\",\"mr\":2,\"children\":\"By: Abhilaksh Singh Reen\"}],[\"$\",\"$L1d\",null,{\"socialMediaProfiles\":[{\"network_name\":\"LinkedIn\",\"profile_url\":\"https://www.linkedin.com/in/abhilaksh-singh-837901210/\",\"profile_display_name\":\"Abhilaksh Singh Reen\"},{\"network_name\":\"Twitter\",\"profile_url\":\"https://x.com/TheVeteran06\",\"profile_display_name\":\"The Veteran 06\"},{\"network_name\":\"GitHub\",\"profile_url\":\"https://github.com/AbhilakshSinghReen\",\"profile_display_name\":\"Abhilaksh Singh Reen\"}]}]]}]\n"])</script><script>self.__next_f.push([1,"1e:I[6652,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\n1f:I[6981,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\n20:I[2818,[\"98\",\"static/chunks/98-7f6363f9ac68c942.js\",\"134\",\"static/chunks/134-9729e0afcc6dfdfe.js\",\"830\",\"static/chunks/830-8a0df588e7c84864.js\",\"748\",\"static/chunks/748-1f14ee6eb3d7029a.js\",\"411\",\"static/chunks/411-e5dcfc2304d91b2f.js\",\"533\",\"static/chunks/app/%5BcategorySlug%5D/%5BpostOrSeriesSlug%5D/page-b4c214dd448204e1.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"1c:[\"$\",\"$Lc\",null,{\"mt\":5,\"mb\":5,\"pb\":2,\"sx\":{\"width\":\"100%\",\"display\":\"flex\",\"flexDirection\":\"column\",\"justifyContent\":\"flex-start\",\"alignItems\":\"center\"},\"children\":[\"$\",\"$L15\",null,{\"container\":true,\"spacing\":2,\"mt\":4,\"mb\":4,\"children\":[[\"$\",\"$L15\",\"/ml-ops/gpu-vs-cpu-performance-for-ml-inference-workflows\",{\"item\":true,\"xs\":12,\"sm\":6,\"md\":4,\"lg\":3,\"children\":[\"$\",\"$Lf\",null,{\"href\":\"/ml-ops/gpu-vs-cpu-performance-for-ml-inference-workflows\",\"passHref\":true,\"style\":{\"textDecoration\":\"none\"},\"children\":[\"$\",\"$L1e\",null,{\"sx\":{\"width\":\"100%\",\"height\":\"100%\",\"boxShadow\":\"1px 1px 1px 1px \\\"#eeeeee\\\"\",\"\u0026:hover\":{\"boxShadow\":\"3px 3px 3px 3px \\\"#eeeeee\\\"\",\"cursor\":\"pointer\"}},\"children\":[[\"$\",\"$L1f\",null,{\"component\":\"img\",\"height\":\"150\",\"image\":\"/media/images/gpu-vs-cpu-performance-for-ml-inference-workflows-thumbnail.jpg\",\"alt\":\"ML Inference Performance on GPU and CPU across different batch sizes.\",\"sx\":{\"objectFit\":\"cover\"}}],[\"$\",\"$L20\",null,{\"children\":[[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"h6\",\"component\":\"h2\",\"children\":[\"\",\" \",\"ML Inference Performance on GPU and CPU across different batch sizes.\"]}],[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"overflow\":\"hidden\",\"textOverflow\":\"ellipsis\",\"display\":\"-webkit-box\",\"WebkitLineClamp\":\"3\",\"WebkitBoxOrient\":\"vertical\"},\"children\":\"A comparison of ML inference speed and memory consumption across various batch sizes on both GPU and CPU.\"}],[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\",\"display\":\"flex\",\"flexDirection\":\"row\",\"justifyContent\":\"flex-end\",\"alignItems\":\"center\"},\"children\":[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"children\":\"08m Read\"}]}],false]}]]}]}]}],[\"$\",\"$L15\",\"/ml-ops/fastapi-onnx-backend\",{\"item\":true,\"xs\":12,\"sm\":6,\"md\":4,\"lg\":3,\"children\":[\"$\",\"$Lf\",null,{\"href\":\"/ml-ops/fastapi-onnx-backend\",\"passHref\":true,\"style\":{\"textDecoration\":\"none\"},\"children\":[\"$\",\"$L1e\",null,{\"sx\":{\"width\":\"100%\",\"height\":\"100%\",\"boxShadow\":\"1px 1px 1px 1px \\\"#eeeeee\\\"\",\"\u0026:hover\":{\"boxShadow\":\"3px 3px 3px 3px \\\"#eeeeee\\\"\",\"cursor\":\"pointer\"}},\"children\":[[\"$\",\"$L1f\",null,{\"component\":\"img\",\"height\":\"150\",\"image\":\"/media/images/fastapi-onnx-backend-thumbnail.jpg\",\"alt\":\"Serving an ONNX Model using FastAPI\",\"sx\":{\"objectFit\":\"cover\"}}],[\"$\",\"$L20\",null,{\"children\":[[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"h6\",\"component\":\"h2\",\"children\":[\"\",\" \",\"Serving an ONNX Model using FastAPI\"]}],[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"overflow\":\"hidden\",\"textOverflow\":\"ellipsis\",\"display\":\"-webkit-box\",\"WebkitLineClamp\":\"3\",\"WebkitBoxOrient\":\"vertical\"},\"children\":\"Learn how to serve an ONNX model with FastAPI.\"}],[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\",\"display\":\"flex\",\"flexDirection\":\"row\",\"justifyContent\":\"flex-end\",\"alignItems\":\"center\"},\"children\":[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"children\":\"06m Read\"}]}],false]}]]}]}]}],[\"$\",\"$L15\",\"/ml-ops/node-express-onnx-backend\",{\"item\":true,\"xs\":12,\"sm\":6,\"md\":4,\"lg\":3,\"children\":[\"$\",\"$Lf\",null,{\"href\":\"/ml-ops/node-express-onnx-backend\",\"passHref\":true,\"style\":{\"textDecoration\":\"none\"},\"children\":[\"$\",\"$L1e\",null,{\"sx\":{\"width\":\"100%\",\"height\":\"100%\",\"boxShadow\":\"1px 1px 1px 1px \\\"#eeeeee\\\"\",\"\u0026:hover\":{\"boxShadow\":\"3px 3px 3px 3px \\\"#eeeeee\\\"\",\"cursor\":\"pointer\"}},\"children\":[[\"$\",\"$L1f\",null,{\"component\":\"img\",\"height\":\"150\",\"image\":\"/media/images/node-express-onnx-backend-thumbnail.jpg\",\"alt\":\"Express.js API for Inference using an ONNX Model\",\"sx\":{\"objectFit\":\"cover\"}}],[\"$\",\"$L20\",null,{\"children\":[[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"h6\",\"component\":\"h2\",\"children\":[\"\",\" \",\"Express.js API for Inference using an ONNX Model\"]}],[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"overflow\":\"hidden\",\"textOverflow\":\"ellipsis\",\"display\":\"-webkit-box\",\"WebkitLineClamp\":\"3\",\"WebkitBoxOrient\":\"vertical\"},\"children\":\"Deploying an ONNX Model using Express.js.\"}],[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\",\"display\":\"flex\",\"flexDirection\":\"row\",\"justifyContent\":\"flex-end\",\"alignItems\":\"center\"},\"children\":[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"children\":\"08m Read\"}]}],false]}]]}]}]}],[\"$\",\"$L15\",\"/ml-ops/onnxruntime-web-inference-in-react\",{\"item\":true,\"xs\":12,\"sm\":6,\"md\":4,\"lg\":3,\"children\":[\"$\",\"$Lf\",null,{\"href\":\"/ml-ops/onnxruntime-web-inference-in-react\",\"passHref\":true,\"style\":{\"textDecoration\":\"none\"},\"children\":[\"$\",\"$L1e\",null,{\"sx\":{\"width\":\"100%\",\"height\":\"100%\",\"boxShadow\":\"1px 1px 1px 1px \\\"#eeeeee\\\"\",\"\u0026:hover\":{\"boxShadow\":\"3px 3px 3px 3px \\\"#eeeeee\\\"\",\"cursor\":\"pointer\"}},\"children\":[[\"$\",\"$L1f\",null,{\"component\":\"img\",\"height\":\"150\",\"image\":\"/media/images/react-digit-recog-app-final.jpg\",\"alt\":\"ONNXRuntime Inference in a React App\",\"sx\":{\"objectFit\":\"cover\"}}],[\"$\",\"$L20\",null,{\"children\":[[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"h6\",\"component\":\"h2\",\"children\":[\"\",\" \",\"ONNXRuntime Inference in a React App\"]}],[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"sx\":{\"overflow\":\"hidden\",\"textOverflow\":\"ellipsis\",\"display\":\"-webkit-box\",\"WebkitLineClamp\":\"3\",\"WebkitBoxOrient\":\"vertical\"},\"children\":\"Inferencing on an ONNX model in a React App using ONNXRuntime Web.\"}],[\"$\",\"$Lc\",null,{\"sx\":{\"width\":\"100%\",\"display\":\"flex\",\"flexDirection\":\"row\",\"justifyContent\":\"flex-end\",\"alignItems\":\"center\"},\"children\":[\"$\",\"$Le\",null,{\"gutterBottom\":true,\"variant\":\"p\",\"component\":\"p\",\"children\":\"08m Read\"}]}],false]}]]}]}]}]]}]}]\n"])</script></body></html>